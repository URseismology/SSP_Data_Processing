{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"17zmEMEQ8p1-xpxNyBJTX2IXI2S5B-0UB","timestamp":1686760630611}]}},"cells":[{"cell_type":"code","source":["# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n","# Author: Tolulope Olugboji\n","# Date:  October 10, 2013\n","# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n","#\n","# Objective:   Read SAC Files [OBS DATA ONLY] from Kawakatsu Japanese project...\n","#              Scan a huge record database and parse event times, Conduct Quality Check,\n","#             and visualize seismograms semi-autonomously\n","#\n","#\n","# Code scans through data and displays each band pass window for the vertical seismogram\n","# Modules include dateTime, read_Records, signal_filtering, envelopes, output_Clear, tauP_routines\n","#\n","#\n","\n","from obspy import UTCDateTime\n","from obspy import read\n","import obspy.signal\n","import time, sys, os\n","from IPython.display import display, clear_output\n","from obspy.taup.taup import getTravelTimes\n","from obspy.signal import rotate_new\n","\n","def traceTagTimeSlow(threeCompStrm, travelTimeDic, pTime):\n","    \"tag the header t0 with first arrival phase name\"\n","\n","    # Write Phase Name, Phase Slowness and Phase ?\n","    for iCmp in range(3):\n","        threeCompStrm[iCmp].stats.sac['t0'] = pTime\n","        threeCompStrm[iCmp].stats.sac['user0'] =  travelTimeDic['dT/dD']\n","        threeCompStrm[iCmp].stats.sac['kt0'] =  travelTimeDic['phase_name']\n","\n","\n","def traceTagQC(threeCompStrm, pTime):\n","    \"tag the header t1, to indicate QC pass\"\n","\n","    # Put QC tag in here ...\n","    for iCmp in range(3):\n","        threeCompStrm[iCmp].stats.sac['t1'] = pTime\n","\n","def iterateProjectData(projectDir, yearDir):\n","    # traverse project directory, and return directory tree for\n","    # data - Year, Station - Files...\n","    # In addition, return a list of dictionaries for Station:Orientation Codes.\n","    # This is required for rotating SAC Files\n","    #\n","    # Return: File List  by [Year, Station] ? What structure to use for this???\n","    #         List of SAC-Dictionaries with Station:Orientation_Code for each Year\n","\n","    # staticOrientation[0] = 2005 ; staticOrientation[1] = 2006; staticOrientation[2] = 2007\n","    staticOrientation = [{'t06':228.002,\n","                          't08':324.55,\n","                          't09':13.3069,\n","                          't12':300.839,\n","                          't15':350.413,\n","                          't17':20.0313,\n","                          't18':180.928,\n","                          't19':299.896,\n","                          't21':334.879,},\n","\n","                         {'t01':239.707,\n","                          't02':194.674,\n","                          't03':-0.794498,\n","                          't05':100.041,\n","                          't06':68.9703,\n","                          't07':325.232,\n","                          't08':15.5905,\n","                          't09':285.814,\n","                          't11':8.16505,\n","                          't12':177.762,\n","                          't13':223.077,},\n","\n","                         {'t02':158.52,\n","                          't03':193.695,\n","                          't05':300.223,\n","                          't06':152.368,\n","                          't07':1.09913,\n","                          't09':295.433,\n","                          't12':55.9152,\n","                          't13':84.3507,\n","                          't15':241.973,\n","                          't16':132.348,\n","                          't18':353.411,}\n","\n","                         ]\n","\n","    projectYearDir = projectDir + yearDir\n","\n","    if (yearDir == \"2005/\"):\n","        stationDirs = staticOrientation[0].keys()\n","        orientationCodeByYear = staticOrientation[0]\n","    elif (yearDir == \"2006/\"):\n","        stationDirs = staticOrientation[1].keys()\n","        orientationCodeByYear = staticOrientation[1]\n","    elif (yearDir == \"2007/\"):\n","        stationDirs = staticOrientation[2].keys()\n","        orientationCodeByYear = staticOrientation[2]\n","\n","    print \"No of stations: \", len(stationDirs), \"Stations: \", stationDirs\n","    listStationFiles = []\n","\n","    for stationDir in stationDirs:\n","        projectYearStationDir = projectYearDir + stationDir\n","        #print \"Dirs: \", projectYearStationDir\n","        fileNames = !ls $projectYearStationDir/*Z\n","        #print \"No of files in station, \", stationDir, \" :\", len(fileNames)\n","        listStationFiles.append(fileNames)\n","\n","    return stationDirs, listStationFiles, orientationCodeByYear\n","\n","\n","    #return stations, fileLists, OrientationDict\n","\n","def read3Channels(DataDir, fileMantissa, Fileformat):\n","    #Code snippet to take file name, and return 3component Stream.\n","    \"Code snippet to take file name, and return 3component Stream.\"\n","    vertFile = fileMantissa+\"Z\";\n","    radFile = fileMantissa+\"H1\";\n","    transFile = fileMantissa+\"H2\"\n","    print \"Names: \", vertFile, radFile, transFile;\n","    # read each record triplet, and display ...\n","    threeCompStrm = read(DataDir + '/' + vertFile);\n","    threeCompStrm += read(DataDir + '/' + radFile);\n","    threeCompStrm += read(DataDir + '/' + transFile);\n","    return threeCompStrm\n","\n","def preProcessStream(threeCompStrm, noiseWindowSec, signalWindowSec):\n","    \"Slice Trace, Demean, Detrend, and HighPass?\"\n","    # noiseWindowSec : time before arrival P time\n","    # signalWindowSec : time after arrival P time\n","\n","    #!!!! ................................. Load Depth, Distance, Then Compute Travel Time\n","    evntDistDeg = threeCompStrm[0].stats.sac['gcarc'];\n","    evntDep = threeCompStrm[0].stats.sac['evdp'];\n","    strtTime = threeCompStrm[0].stats['starttime'];\n","    tt = getTravelTimes(delta=evntDistDeg, depth = evntDep, model='ak135')\n","    pTime = tt[0]['time']\n","\n","    biasLeft = noiseWindowSec; biasRight = signalWindowSec\n","    #print \"Windows ...\", biasLeft, biasRight, \"Time \", strtTime\n","\n","    #1. Slice And Tag ...\n","    procStream = threeCompStrm.slice(strtTime+pTime - biasLeft, strtTime+pTime+biasRight)\n","    traceTagTimeSlow(procStream, tt[0], biasLeft)\n","\n","    # Demean, Detrend, and, HighPass? Yes with 50s [1/50 = 0.02 Hz]  *******\n","\n","    lowFreq = 0.02\n","    procStream.detrend(type=\"demean\"); procStream.detrend(type=\"simple\")\n","    procStream.filter(\"highpass\", freq=lowFreq)\n","\n","\n","    return procStream\n","\n","def readHeaders(trace):\n","    \"Read relevant header information ...\"\n","    return {'gcarc': trace.stats.sac['gcarc'], 'evdp':trace.stats.sac['evdp'],\n","            'starttime':trace.stats['starttime'], 'o': trace.stats['sac']['o'], 'delta': trace.stats['delta'],\n","            'baz':trace.stats.sac['baz']}\n","\n","def rotateStream2ZRT(threeCompStrm, H1Azim):\n","    \"Load 3 component stream and rotate from ZH1H2 into ZRT.\"\n","    #rotate_new from krischer / obspy might be useful ..\n","    baz = threeCompStrm[1].stats.sac['baz']\n","\n","    dipZcomp = -90; dipH1comp = 0.0; dipH2comp = 0.0\n","    azimZcomp = 0; azimH1comp = H1Azim; azimH2comp = (H1Azim + 90.0) % 360\n","    print \"H1 azim: \", azimH1comp, \"H2 azim: \", azimH2comp\n","    zData = threeCompStrm[0].data ; H1Data = threeCompStrm[1].data ; H2Data = threeCompStrm[2].data;\n","    [Z, N, E] = rotate_new.rotate2ZNE(zData, azimZcomp, dipZcomp, H1Data, azimH1comp, dipH1comp, \\\n","                                      H2Data,azimH2comp, dipH2comp)\n","\n","    [R, T] = rotate_new.rotate_NE_RT(N, E, baz)\n","\n","    threeCompStrm[0].data = Z\n","    threeCompStrm[1].data = R\n","    threeCompStrm[2].data = T\n","\n","\n","\n","def saveStream(threeCompStrm, outDir, fileMantissa):\n","    # Code Snippet to Take Processed Stream and Save to Hard-Disk\"\n","    \"Save Stream to Directory, Default Output is SAC file ...\"\n","    print \"Saving trace to: \", outDir+fileMantissa+\".[ZRT]\"\n","\n","    vertFile = fileMantissa+\"Z\";\n","    radFile = fileMantissa+\"R\";\n","    transFile = fileMantissa+\"T\"\n","\n","    if (os.path.isdir(outDir) ):\n","        print \"Dir exists: \"\n","        threeCompStrm[0].write(outDir + vertFile, format=\"SAC\")\n","        threeCompStrm[1].write(outDir + radFile, format=\"SAC\")\n","        threeCompStrm[2].write(outDir + transFile, format=\"SAC\")\n","    else:\n","        print \"Make Directory, then save..\"\n","        os.makedirs(outDir)\n","        threeCompStrm[0].write(outDir + vertFile, format=\"SAC\")\n","        threeCompStrm[1].write(outDir + radFile, format=\"SAC\")\n","        threeCompStrm[2].write(outDir + transFile, format=\"SAC\")\n","\n","\n","def runBandCheckQC(threeCompStrm, noiseWin, signalWin):\n","    from copy import deepcopy\n","    # run signal to noise in each window and tag phas appropriately\n","    #################### FREQ Windows\n","    cornerFreq = 0.07\n","    lowFreqA = 0.07\n","    highFreqA = 0.25\n","    lowFreqB = 0.25\n","    highFreqB = 2\n","    #################### End FREQ Windows\n","\n","    # Make copy of stream ...\n","    lowFrqStrm = deepcopy(threeCompStrm)\n","    midFrqStrm = deepcopy(threeCompStrm)\n","    highFrqStrm = deepcopy(threeCompStrm)\n","\n","    # Band Pass these Copies\n","    #lowFrqStrm.filter(\"lowpass\", freq=cornerFreq);\n","    lowFrqStrm.filter(\"bandpass\", freqmin=0.01, freqmax=0.07, corners=2);\n","    midFrqStrm.filter(\"bandpass\", freqmin=lowFreqA, freqmax=highFreqA);\n","    highFrqStrm.filter(\"bandpass\", freqmin=lowFreqB, freqmax=highFreqB);\n","\n","    zEnvlpBands = []\n","    zComps = []\n","    allSigNoise = []\n","\n","    # Pick Out vertical Components of Bands and append to list for signal analysis\n","    zEnvlpBands.append( obspy.signal.filter.envelope(lowFrqStrm[0].data) )\n","    zComps.append( lowFrqStrm[0].data )\n","\n","    zEnvlpBands.append( obspy.signal.filter.envelope(midFrqStrm[0].data) )\n","    zComps.append( midFrqStrm[0].data )\n","\n","    zEnvlpBands.append( obspy.signal.filter.envelope(highFrqStrm[0].data) )\n","    zComps.append( highFrqStrm[0].data )\n","\n","\n","    plt.figure(figsize=(10,4))\n","\n","    # Iterate through bands and do signal to noise computation ...\n","    for iterBands in range( len(zEnvlpBands) ):\n","\n","        plt.subplot(3,1,iterBands+1)\n","\n","        zEnvlpBand = zEnvlpBands[iterBands]\n","        zComp = zComps[iterBands]\n","\n","        t = np.linspace(0, noiseWin+signalWin, len(zEnvlpBand) )\n","        noise =  zEnvlpBand[t<100];  signal =  zEnvlpBand[t >100];\n","\n","        sig2noise = np.average(np.absolute(signal)) / np.average(np.absolute(noise));\n","        allSigNoise.append( sig2noise )\n","        print \"Signal to Noise: \", np.average(np.absolute(signal)), np.average(np.absolute(noise)), sig2noise\n","\n","        plt.plot(t, zComp)\n","        plt.plot(t, zEnvlpBand)\n","\n","        if( sig2noise > 2):\n","            plt.plot(t[0:len(noise)], noise, 'r')\n","\n","\n","    plt.show()\n","    sig2noiseMax = np.amax(allSigNoise)\n","    print \"Maximum Signal to Noise across 3 Frequency bands: \", sig2noiseMax\n","\n","    if( sig2noiseMax > 2):\n","        traceTagQC(threeCompStrm, noiseWin)\n","        tagStatus = True\n","    else:\n","        tagStatus = False\n","\n","    return tagStatus;\n","\n","\n","########################### END OF FUNCTION DEFINITIONS #########################################################\n","#!!!!!!!!!!!!!!!!!!!!!!!!!!! BEGIN WORKFLOW HERE ...... !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n","##++--- ---+ !!!!!!! Work on Work flow using the helper functions now ...\n","inDir = \"/Users/tmo22/Documents/JapaneseProject/RawData/\"\n","projectDirs = ['sspData/', 'borehole.farm/']\n","yearDirs = ['2005/', '2006/', '2007/']\n","outDir = \"/Users/tmo22/Documents/JapaneseProject/ProcData/\"\n","\n","\n","# Select particular project-Year-Dir - (iterate in the future) - and parse to method to return list of files\n","projectDir = inDir + projectDirs[0]\n","for yearDir in yearDirs[1:3]:\n","#for yearDir in yearDirs:\n","\n","    # stationFiles = iterateProjectData(projectDir, yearDir)\n","    [stations, listFilebyStation, orientationCde] = iterateProjectData(projectDir, yearDir)\n","\n","\n","    #for iterStation in range(8,11,1):\n","    for iterStation in range( len(stations) ):\n","        # Use shell command to recover all vertical records\n","        DataDir = projectDir + yearDir + stations[iterStation] + '/'\n","        DataFiles = listFilebyStation[iterStation]\n","\n","        numRecs = len(DataFiles)\n","\n","        listGoodTraces = []\n","        cntGoodTraces = 0\n","\n","        #sys.exit(\"Demo for station iteration ..\")\n","        stationAzim = orientationCde[stations[iterStation]]\n","\n","        #for iterDataFile in range(3):\n","        for iterDataFile in range(len(DataFiles)):\n","\n","            # Pick out file name ...\n","            DataFile = DataFiles[iterDataFile]\n","            fileSplit = DataFile.split('/'); indxLast = len(fileSplit); fileName =  fileSplit[indxLast-1];\n","            fileHead = fileName[0:len(fileName)-1]\n","\n","            # ....................................0. Display SCAN status\n","            print \"Dir: \", yearDir\n","            print \"Station: \", stations[iterStation]\n","            print \"H1 Orientation Azim \", stationAzim\n","            print \"Number of records: \", numRecs;\n","            print \"Reading \", DataDir + fileHead, \"File \", iterDataFile, \" of \", len(DataFiles)\n","            print \"No of QC tagged records: \", cntGoodTraces, \"List:  \", listGoodTraces\n","\n","            #  ................................... 1. READ!\n","            threeCompStrm = read3Channels(DataDir, fileHead, \"SAC\")\n","            #threeCompStrm[0].plot(); threeCompStrm[1].plot(); threeCompStrm[2].plot();\n","\n","            # Trace slicing parameters.........  2. prePROCESS!\n","            noiseWindow = 100; signalWindow = 600\n","            procStrm = preProcessStream(threeCompStrm,noiseWindow, signalWindow)\n","            #procStrm[0].plot(type=\"relative\", number_of_ticks=4);\n","            #procStrm[1].plot(type=\"relative\", number_of_ticks=4);\n","            #procStrm[2].plot(type=\"relative\", number_of_ticks=4);\n","\n","             # ............................ 3.ROTATE!\n","            rotateStream2ZRT(procStrm,stationAzim)\n","            #procStrm[0].plot(type=\"relative\", number_of_ticks=4);  procStrm[1].plot(type=\"relative\", number_of_ticks=4);\n","            #procStrm[2].plot(type=\"relative\", number_of_ticks=4);\n","            #print readHeaders(procStrm[0])\n","\n","\n","            # ............................. 4. doQC and TAGPHASE ..\n","            isGood = runBandCheckQC(procStrm, noiseWindow, signalWindow)\n","\n","            if (isGood):\n","                listGoodTraces.append(iterDataFile)\n","                cntGoodTraces += 1\n","\n","            procStrm[0].plot(type=\"relative\", number_of_ticks=4)\n","\n","            #time.sleep(1)\n","            clear_output()\n","\n","\n","            # ............................. 5. saveSTREAM to outputDIR ..\n","            outDirSave = outDir + projectDirs[0] + yearDir + stations[iterStation] + '/'\n","            saveStream(procStrm, outDirSave, fileHead)\n","\n","\n","\n"],"outputs":[{"output_type":"stream","text":["Saving trace to:  /Users/tmo22/Documents/JapaneseProject/ProcData/sspData/2006/t05/t05.061129.153844..[ZRT]\n","Dir exists: \n","Dir:  2006/\n","Station:  t05\n","H1 Orientation Azim  100.041\n","Number of records:  597\n","Reading  /Users/tmo22/Documents/JapaneseProject/RawData/sspData/2006/t05/t05.061129.230815. File  63  of  597\n","No of QC tagged records:  8 List:   [1, 3, 6, 8, 15, 42, 43, 61]\n","Names:  t05.061129.230815.Z t05.061129.230815.H1 t05.061129.230815.H2\n","H1 azim: "],"name":"stdout"},{"output_type":"stream","text":[" 100.041 H2 azim:  190.041\n","Signal to Noise: "],"name":"stdout"},{"output_type":"stream","text":[" 1800.31946106 4029.08689183 0.446830636665\n","Signal to Noise: "],"name":"stdout"},{"output_type":"stream","text":[" 18114.7004697 16272.7763689 1.11319052502\n","Signal to Noise: "],"name":"stdout"},{"output_type":"stream","text":[" 31121.4100065 34473.4983411 0.902763325572\n"],"name":"stdout"}],"metadata":{"id":"QOgi1L6Dw_mX","outputId":"6ef328b7-8aad-442c-dbba-5af79c41afd8"},"execution_count":null},{"cell_type":"code","source":["21 # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n","# Author: Tolulope Olugboji\n","# Date:  October 10, 2013\n","#\n","# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n","#\n","# Objective:  Read SEED files from Kawakatsu BoreHole Data\n","#             Scan a huge record database and parse event times, Conduct Quality Check,\n","#             and visualize seismograms semi-autonomously\n","#\n","#\n","# Code scans through data and displays each band pass window for the vertical seismogram\n","# Modules include dateTime, read_Records, signal_filtering, envelopes, output_Clear, tauP_routines\n","#\n","#\n","\n","from obspy import UTCDateTime\n","from obspy.xseed import Parser\n","from obspy import read\n","from obspy.core.util import locations2degrees\n","from obspy.core.util.geodetics import gps2DistAzimuth\n","import obspy.signal\n","import time, sys, os\n","from IPython.display import display, clear_output\n","from obspy.taup.taup import getTravelTimes\n","\n","def updateSacHeaders(trace, sacDics):\n","\n","    #SAC Dics:  {'elevation': -6036.7,\n","    #            'evlon': 175.583,\n","    #            'evlat': -18.343,\n","    #            'longitude': 159.9632,\n","    #            'evDep': 251.0,\n","    #            'local_depth': 0.0,\n","    #            'latitude': 41.0797,\n","    #            'evMag': 5.6}\n","\n","    print \"SAC DICS In the trace updater...\", sacDics\n","    trace.stats.sac['evla'] = sacDics['evlat']\n","    trace.stats.sac['evlo'] = sacDics['evlon']\n","    trace.stats.sac['evdp'] = sacDics['evDep']\n","\n","    trace.stats.sac['stla'] = sacDics['latitude']\n","    trace.stats.sac['stlo'] = sacDics['longitude']\n","    trace.stats.sac['stdp'] = sacDics['elevation']\n","\n","    trace.stats.sac['gcarc'] = locations2degrees( sacDics['latitude'], sacDics['longitude'],\n","                                                 sacDics['evlat'], sacDics['evlon'] )\n","\n","    dist, az, baz = gps2DistAzimuth(sacDics['evlat'], sacDics['evlon'], sacDics['latitude'],\n","                                   sacDics['longitude'] )\n","\n","    trace.stats.sac['az'] = az\n","    trace.stats.sac['baz'] = baz\n","\n","    trace.stats.sac['mag'] = sacDics['evMag']\n","\n","\n","    # Update Component Azimuth, Useful for external rotation routine ...\n","    if ( trace.stats['channel'] == 'BHN' ):\n","        trace.stats.sac['cmpaz'] = 0.0\n","    elif ( trace.stats['channel'] == 'BHE' ):\n","        trace.stats.sac['cmpaz'] = 90.0\n","    elif ( trace.stats['channel'] == 'BHZ' ):\n","        trace.stats.sac['cmpaz'] = 0.0\n","\n","\n","\n","\n","def saveStream(seedStrm, outDir, fileMantissa, evDics, fileFormat):\n","    # Code Snippet to Take Processed Stream and Save to Hard-Disk\"\n","    \"Save Stream to Directory, Default Output is SAC file ...\"\n","    print \"Saving trace to: \", outDir+fileMantissa+\".[ZRT]\"\n","\n","    # Station routing logic - Save - LoadSAC - UpdateHeaders - Save\n","    for trace in seedStrm:\n","        if (trace.stats['station'] == 'WP1'):\n","            fDir = outDir+'WP1/'+fileMantissa+trace.stats['channel']\n","            print \"WP1 Folder ..\", fDir\n","\n","            # Stitch dictionaries together ...\n","            stDics = {'latitude': 19.2975, 'local_depth': 0.0, 'elevation': -6282.2, 'longitude': 135.0992}\n","            sacDics = dict( evDics.items()+stDics.items() )\n","\n","\n","            # Route Trace to appropriate Directory [Create if necessary]\n","            if (os.path.isdir(outDir + 'WP1/') ):\n","                print \"Dir exists: \"\n","\n","                # .................................     Save\n","                trace.write(fDir, format=fileFormat)\n","\n","                # .................................     LOAD SAC\n","                noHeaders = read(fDir)\n","\n","                # .................................     Update Headers...\n","                updateSacHeaders(noHeaders[0], sacDics)\n","\n","                # .................................     Save\n","                noHeaders[0].write(fDir, format=fileFormat)\n","            else:\n","                print \"Make Directory, then save..\"\n","                os.makedirs(outDir + 'WP1/')\n","                # .................................     Save\n","                trace.write(fDir, format=fileFormat)\n","\n","                # .................................     LOAD SAC\n","                noHeaders = read(fDir)\n","\n","                # .................................     Update Headers...\n","                updateSacHeaders(noHeaders[0], sacDics)\n","                #print noHeaders[0].stats['sac']\n","\n","                # .................................     Save\n","                noHeaders[0].write(fDir, format=fileFormat)\n","\n","\n","        elif (trace.stats['station'] == 'WP2'):\n","            fDir = outDir+'WP2/'+fileMantissa+trace.stats['channel']\n","            print \"WP2 Folder ..\", fDir\n","\n","            # Stitch dictionaries together ...\n","            stDics = {'latitude': 41.0797, 'local_depth': 0.0, 'elevation': -6036.7, 'longitude': 159.9632}\n","            sacDics = dict( evDics.items()+stDics.items() )\n","\n","\n","            # Route Trace to appropriate Directory [Create if necessary]\n","            if (os.path.isdir(outDir + 'WP2/') ):\n","                print \"Dir exists: \"\n","                # .................................     Save\n","                trace.write(fDir, format=fileFormat)\n","\n","                # .................................     LOAD SAC\n","                noHeaders = read(fDir)\n","\n","                # .................................     Update Headers...\n","                updateSacHeaders(noHeaders[0], sacDics)\n","                #print noHeaders[0].stats\n","\n","                # .................................     Save\n","                noHeaders[0].write(fDir, format=fileFormat)\n","\n","            else:\n","                print \"Make Directory, then save..\"\n","                os.makedirs(outDir + 'WP2/')\n","                # .................................     Save\n","                trace.write(fDir, format=fileFormat)\n","\n","                # .................................     LOAD SAC\n","                noHeaders = read(fDir)\n","\n","                # .................................     Update Headers...\n","                updateSacHeaders(noHeaders[0], sacDics)\n","                #print noHeaders[0].stats\n","\n","                # .................................     Save\n","                noHeaders[0].write(fDir, format=fileFormat)\n","\n","        #print \"SAC Dics: \", sacDics\n","\n","def getEventCordinates(line):\n","\n","\n","    if ( not(line) ):\n","        # Code for earthquakes without event records ...\n","        sacDic = {'evlat': 0.0, 'evlon': 0.0, 'evMag': 0.0, 'evDep': 0.0}\n","    else:\n","        cols = line.split()\n","\n","        evlat = float(cols[1])\n","        evlon = float(cols[3])\n","\n","        if (cols[2] == 'S'):\n","            evlat = evlat * -1.0\n","        elif(cols[4] == 'W'):\n","            evlon = evlon * -1.0\n","\n","        evMag = float(cols[6])\n","        evDep = float(cols[5])\n","\n","        print cols\n","        print \"Event Lat\", evlat, \"Evnt Lon\", evlon, \"Mag\", evMag, \"Depth\", evDep\n","\n","        sacDic = {'evlat': evlat, 'evlon': evlon, 'evMag': evMag, 'evDep': evDep}\n","\n","    return sacDic\n","\n","\n","\n","\n","def getSACEventDic(timeStart):\n","\n","    dataYr = UTCDateTime(timeStart).year\n","    lookUpDateStr = UTCDateTime(timeStart).strftime(\"%Y%m%d%H\")\n","    print \"Year: \", dataYr\n","\n","    foundDate = False;\n","    evntInfo = getEventCordinates(\"\") # Initialize event info to zero for no match ..\n","\n","\n","\n","    # Look up the eventfiles using year\n","    inEventDir = \"/Users/tmo22/Documents/JapaneseProject/RawData/borehole.farm/eventlist/\"\n","    if(dataYr == 2000):\n","        # read 2000list\n","        fName = inEventDir + \"2000all.list\"\n","        eventFile = open(fName, 'r');\n","        eventTable = eventFile.readlines()\n","        eventFile.close()\n","\n","        for line in eventTable:\n","\n","            yr = int( line[0:4] )\n","            month = int( line[4:6] )\n","            day = int( line[6:8] )\n","            hr = int( line[8:10] )\n","            mins = int( line[10:12] )\n","\n","            eventDate = UTCDateTime(yr, month, day, hr, mins)\n","            #print yr, month, day, hr, mins\n","\n","            fileDateStr =  UTCDateTime(eventDate).strftime(\"%Y%m%d%H\");\n","            foundDate = UTCDateTime(fileDateStr) == UTCDateTime(lookUpDateStr)\n","            #print \"Value on File YrMnthDayHrMin: \", fileDateStr, \"Found? \", cmprDate\n","            #print \"Look up Date Str: \", fileDateStr, \"String initialize: \", line[0:12]\n","\n","            if (foundDate):\n","                print \"Look up Date [Data]: \", UTCDateTime(timeStart).year, UTCDateTime(timeStart).month, UTCDateTime(timeStart).day, UTCDateTime(timeStart).hour, UTCDateTime(timeStart).minute\n","                print \"Look up Date [Event]: \", yr, month, day, hr, mins\n","                print \"Event Info: \", line\n","\n","                ## Read up Event Long & Latitude\n","                evntInfo = getEventCordinates(line)\n","                break\n","\n","    elif(dataYr == 2001):\n","        # read 2001list\n","        fName = inEventDir + \"2001all.list\"\n","        eventFile = open(fName, 'r');\n","        eventTable = eventFile.readlines()\n","        eventFile.close()\n","\n","        for line in eventTable:\n","\n","            yr = int( line[0:4] )\n","            month = int( line[4:6] )\n","            day = int( line[6:8] )\n","            hr = int( line[8:10] )\n","            mins = int( line[10:12] )\n","\n","            eventDate = UTCDateTime(yr, month, day, hr, mins)\n","            #print \"Look up Date [Event]: \", yr, month, day, hr, mins\n","\n","            fileDateStr =  UTCDateTime(eventDate).strftime(\"%Y%m%d%H\");\n","            #print \"Event Date Str: \", fileDateStr, \"Data Date Str: \", lookUpDateStr\n","\n","            foundDate = ( fileDateStr == lookUpDateStr )\n","            #print \"Value on File YrMnthDayHrMin: \", fileDateStr, \"Found? \", cmprDate\n","\n","\n","            if (foundDate):\n","                print \"Look up Date [Data]: \", UTCDateTime(timeStart).year, UTCDateTime(timeStart).month, UTCDateTime(timeStart).day, UTCDateTime(timeStart).hour, UTCDateTime(timeStart).minute\n","                print \"Look up Date [Event]: \", yr, month, day, hr, mins\n","                print \"Event Info: \", line\n","\n","                ## Read up Event Long & Latitude\n","                evntInfo = getEventCordinates(line)\n","                break\n","\n","    elif(dataYr == 2002):\n","        # read 2002list\n","        fName = inEventDir + \"2002all.list\"\n","        eventFile = open(fName, 'r');\n","        eventTable = eventFile.readlines()\n","        eventFile.close()\n","\n","        for line in eventTable:\n","\n","            yr = int( line[0:4] )\n","            month = int( line[4:6] )\n","            day = int( line[6:8] )\n","            hr = int( line[8:10] )\n","            mins = int( line[10:12] )\n","\n","            eventDate = UTCDateTime(yr, month, day, hr, mins)\n","\n","            fileDateStr =  UTCDateTime(eventDate).strftime(\"%Y%m%d%H\");\n","            #foundDate = UTCDateTime(fileDateStr) == UTCDateTime(lookUpDateStr)\n","            foundDate = ( fileDateStr == lookUpDateStr )\n","            #print \"Value on File YrMnthDayHrMin: \", fileDateStr, \"Found? \", cmprDate\n","            #print \"Look up Date Str: \", fileDateStr, \"String initialize: \", line[0:12]\n","\n","            if (foundDate):\n","                print \"Look up Date [Data]: \", UTCDateTime(timeStart).year, UTCDateTime(timeStart).month, UTCDateTime(timeStart).day, UTCDateTime(timeStart).hour, UTCDateTime(timeStart).minute\n","                print \"Look up Date [Event]: \", yr, month, day, hr, mins\n","                print \"Event Info: \", line\n","\n","                ## Read up Event Long & Latitude\n","                evntInfo = getEventCordinates(line)\n","                break\n","\n","    elif(dataYr == 2003):\n","        # read 2003list\n","\n","        fName = inEventDir + '2003all.list'\n","        eventFile = open(fName, 'r');\n","        eventTable = eventFile.readlines()\n","        eventFile.close()\n","\n","        for line in eventTable:\n","\n","            yr = int( line[0:4] )\n","            month = int( line[4:6] )\n","            day = int( line[6:8] )\n","            hr = int( line[8:10] )\n","            mins = int( line[10:12] )\n","\n","            eventDate = UTCDateTime(yr, month, day, hr, mins)\n","\n","            fileDateStr =  UTCDateTime(eventDate).strftime(\"%Y%m%d%H\");\n","            #foundDate = UTCDateTime(fileDateStr) == UTCDateTime(lookUpDateStr)\n","            foundDate = ( fileDateStr == lookUpDateStr )\n","            #print \"Value on File YrMnthDayHrMin: \", fileDateStr, \"Found? \", cmprDate\n","            #print \"Look up Date Str: \", fileDateStr, \"String initialize: \", line[0:12]\n","\n","            if (foundDate):\n","                print \"Look up Date [Data]: \", UTCDateTime(timeStart).year, UTCDateTime(timeStart).month, UTCDateTime(timeStart).day, UTCDateTime(timeStart).hour, UTCDateTime(timeStart).minute\n","                print \"Look up Date [Event]: \", yr, month, day, hr, mins\n","                print \"Event Info: \", line\n","\n","                ## Read up Event Long & Latitude\n","                evntInfo = getEventCordinates(line)\n","                break\n","\n","    elif(dataYr == 2004):\n","        # read 2004list\n","        fName = inEventDir + \"2004all.list\"\n","        eventFile = open(fName, 'r');\n","        eventTable = eventFile.readlines()\n","        eventFile.close()\n","\n","        for line in eventTable:\n","\n","            yr = int( line[0:4] )\n","            month = int( line[4:6] )\n","            day = int( line[6:8] )\n","            hr = int( line[8:10] )\n","            mins = int( line[10:12] )\n","\n","            eventDate = UTCDateTime(yr, month, day, hr, mins)\n","\n","            fileDateStr =  UTCDateTime(eventDate).strftime(\"%Y%m%d%H\");\n","            #foundDate = UTCDateTime(fileDateStr) == UTCDateTime(lookUpDateStr)\n","            foundDate = ( fileDateStr == lookUpDateStr )\n","            #print \"Value on File YrMnthDayHrMin: \", fileDateStr, \"Found? \", cmprDate\n","            #print \"Look up Date Str: \", fileDateStr, \"String initialize: \", line[0:12]\n","\n","            if (foundDate):\n","                print \"Look up Date [Data]: \", UTCDateTime(timeStart).year, UTCDateTime(timeStart).month, UTCDateTime(timeStart).day, UTCDateTime(timeStart).hour, UTCDateTime(timeStart).minute\n","                print \"Look up Date [Event]: \", yr, month, day, hr, mins\n","                print \"Event Info: \", line\n","\n","                ## Read up Event Long & Latitude\n","                evntInfo = getEventCordinates(line)\n","                break\n","\n","    if ( not (foundDate) ):\n","        print \"LookUp Failed\"\n","    return dataYr, evntInfo\n","\n","\n","########################### WorkFlow commences here .......................\n","# ..........................................................................\n","\n","rootDir = \"/Users/tmo22/Documents/JapaneseProject/RawData/\"\n","projectDir = ['sspData/', 'borehole.farm/']\n","\n","\n","# Directory to demo processing: output store for procData\n","outDir = \"/Users/tmo22/Documents/JapaneseProject/ProcData/boreHole/\"\n","\n","outDir = rootDir +  projectDir[1] + 'farmSAC/'# Out SAC First\n","DataDir = rootDir + projectDir[1] + 'farm'\n","\n","# Use shell command to recover all files ...\n","DataFiles = !ls $DataDir\n","numRecs = len(DataFiles)\n","numRecs = 1\n","\n","print DataDir\n","print \"Number of records: \", numRecs;\n","\n","cntTraces = 1\n","cntNoEvnts = 0\n","listBadEvnts = []\n","\n","for DataFile in DataFiles[365:366]:\n","#for DataFile in DataFiles:\n","\n","\n","    clear_output(); stationDic = []\n","\n","    # Reed SEED Automatically. Also Update the Station Dictionary (MetaData) ..\n","    print \"Data Files: \", DataFile, cntTraces, \" of \", len(DataFiles)\n","\n","    seedStrm = read(DataDir+'/'+DataFile)\n","    seedMeta = Parser(DataDir+'/'+DataFile)\n","    #print seedMeta.getCoordinates('PS.WP1..BHE')\n","\n","    # two station read coordinates !!!!! FIX  BUG HERE>>>\n","    #if ( len(seedMeta.getInventory()['stations']) == 2 ):\n","    #    stationDic.append( seedMeta.getCoordinates('PS.WP1..BHE') )\n","    #    stationDic.append( seedMeta.getCoordinates('PS.WP2..BHE') )\n","    #else:\n","    #    stationDic.append( seedMeta.getCoordinates('BHE') )\n","\n","\n","    #print(seedStrm)\n","\n","\n","    # Parse File Mantissa\n","    fileSplit = DataFile.split('.'); indxLast = len(fileSplit);\n","    fileHead =  fileSplit[0] + '.';\n","    print fileHead\n","\n","    # Save Output in SAC\n","\n","    timeLkUp = seedStrm[0].stats.starttime\n","    [yr, evntDic] = getSACEventDic(timeLkUp)\n","    #sacDics = dict( evntDic.items() + stationDic.items() )\n","\n","\n","\n","\n","    # Save stream !!! Rewrite function signature to seperate event dictionaries, and station dictionaries\n","    saveStream(seedStrm, outDir, fileHead, evntDic, \"SAC\")\n","\n","    #seedStrm.plot()\n","    #time.sleep(3)\n","\n","    cntTraces += 1\n","\n","    if (evntDic['evlat'] == 0.0):\n","        cntNoEvnts += 1\n","        listBadEvnts.append(fileHead)\n","\n","    print \"Records with No Events: \", cntNoEvnts, listBadEvnts\n"],"outputs":[{"output_type":"stream","text":["Data Files:  200206110422.seed 1  of  924\n","6 Trace(s) in Stream:\n","PS.WP1..BHE | 2002-06-11T04:22:23.800000Z - 2002-06-11T06:23:53.550000Z | 20.0 Hz, 145796 samples\n","PS.WP1..BHN | 2002-06-11T04:21:05.150000Z - 2002-06-11T06:22:48.950000Z | 20.0 Hz, 146077 samples\n","PS.WP1..BHZ | 2002-06-11T04:21:53.050000Z - 2002-06-11T06:23:33.350000Z | 20.0 Hz, 146007 samples\n","PS.WP2..BHE | 2002-06-11T04:21:21.950000Z - 2002-06-11T06:22:54.650000Z | 20.0 Hz, 145855 samples\n","PS.WP2..BHN | 2002-06-11T04:21:08.950000Z - 2002-06-11T06:22:42.950000Z | 20.0 Hz, 145881 samples\n","PS.WP2..BHZ | 2002-06-11T04:22:13.600000Z - 2002-06-11T06:23:48.800000Z | 20.0 Hz, 145905 samples"],"name":"stdout"},{"output_type":"stream","text":["\n","200206110422.\n","Year:  2002\n","Look up Date [Data]:  2002 6 11 4 22\n","Look up Date [Event]:  2002 6 11 4 22\n","Event Info:  20020611042238.2  58.637 N  155.140 W  132 5.5 ALASKA PENINSULA, UNITED STATES                      \n","\n","['20020611042238.2', '58.637', 'N', '155.140', 'W', '132', '5.5', 'ALASKA', 'PENINSULA,', 'UNITED', 'STATES']\n","Event Lat 58.637 Evnt Lon -155.14 Mag 5.5 Depth 132.0\n","Saving trace to:  /Users/tmo22/Documents/JapaneseProject/RawData/borehole.farm/farmSAC/200206110422..[ZRT]\n","WP1 Folder .. /Users/tmo22/Documents/JapaneseProject/RawData/borehole.farm/farmSAC/WP1/200206110422.BHE\n","Dir exists: \n","SAC DICS In the trace updater... {'elevation': -6282.2, 'evlon': -155.14, 'evlat': 58.637, 'longitude': 135.0992, 'evDep': 132.0, 'local_depth': 0.0, 'latitude': 19.2975, 'evMag': 5.5}\n","WP1 Folder .. /Users/tmo22/Documents/JapaneseProject/RawData/borehole.farm/farmSAC/WP1/200206110422.BHN\n","Dir exists: \n","SAC DICS In the trace updater... {'elevation': -6282.2, 'evlon': -155.14, 'evlat': 58.637, 'longitude': 135.0992, 'evDep': 132.0, 'local_depth': 0.0, 'latitude': 19.2975, 'evMag': 5.5}\n","WP1 Folder .. /Users/tmo22/Documents/JapaneseProject/RawData/borehole.farm/farmSAC/WP1/200206110422.BHZ\n","Dir exists: \n","SAC DICS In the trace updater... {'elevation': -6282.2, 'evlon': -155.14, 'evlat': 58.637, 'longitude': 135.0992, 'evDep': 132.0, 'local_depth': 0.0, 'latitude': 19.2975, 'evMag': 5.5}\n","WP2 Folder .. /Users/tmo22/Documents/JapaneseProject/RawData/borehole.farm/farmSAC/WP2/200206110422.BHE\n","Dir exists: \n","SAC DICS In the trace updater... {'elevation': -6036.7, 'evlon': -155.14, 'evlat': 58.637, 'longitude': 159.9632, 'evDep': 132.0, 'local_depth': 0.0, 'latitude': 41.0797, 'evMag': 5.5}\n","WP2 Folder .. /Users/tmo22/Documents/JapaneseProject/RawData/borehole.farm/farmSAC/WP2/200206110422.BHN\n","Dir exists: \n","SAC DICS In the trace updater... {'elevation': -6036.7, 'evlon': -155.14, 'evlat': 58.637, 'longitude': 159.9632, 'evDep': 132.0, 'local_depth': 0.0, 'latitude': 41.0797, 'evMag': 5.5}\n","WP2 Folder .. /Users/tmo22/Documents/JapaneseProject/RawData/borehole.farm/farmSAC/WP2/200206110422.BHZ\n","Dir exists: \n","SAC DICS In the trace updater..."],"name":"stdout"},{"output_type":"stream","text":[" {'elevation': -6036.7, 'evlon': -155.14, 'evlat': 58.637, 'longitude': 159.9632, 'evDep': 132.0, 'local_depth': 0.0, 'latitude': 41.0797, 'evMag': 5.5}\n","Records with No Events:  0 []\n"],"name":"stdout"}],"metadata":{"id":"bUKgSxEIw_ma","outputId":"808587e6-cbfa-4063-90d1-10004fe41a5b"},"execution_count":null},{"cell_type":"code","source":["# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n","# Author: Tolulope Olugboji\n","# Date:  October 10, 2013\n","# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n","#\n","# Objective:   Read SAC Files [BOREHOLE DATA ONLY] from Kawakatsu Japanese project...\n","#              Scan a huge record database and parse event times, Conduct Quality Check,\n","#             and visualize seismograms semi-autonomously\n","#\n","#\n","# Code scans through data and displays each band pass window for the vertical seismogram\n","# Modules include dateTime, read_Records, signal_filtering, envelopes, output_Clear, tauP_routines\n","#\n","#\n","\n","from obspy import Stream\n","from obspy import UTCDateTime\n","from obspy import read\n","import obspy.signal\n","from obspy.signal import rotate_new\n","import time, sys, os\n","from IPython.display import display, clear_output\n","from obspy.taup.taup import getTravelTimes\n","\n","def smooth(x,window_len=11,window='hanning'):\n","    \"\"\" http://wiki.scipy.org/Cookbook/SignalSmoothsmooth the data using a window with requested size.\n","\n","    This method is based on the convolution of a scaled window with the signal.\n","    The signal is prepared by introducing reflected copies of the signal\n","    (with the window size) in both ends so that transient parts are minimized\n","    in the begining and end part of the output signal.\n","\n","    input:\n","        x: the input signal\n","        window_len: the dimension of the smoothing window; should be an odd integer\n","        window: the type of window from 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\n","            flat window will produce a moving average smoothing.\n","\n","    output:\n","        the smoothed signal\n","\n","    example:\n","\n","    t=linspace(-2,2,0.1)\n","    x=sin(t)+randn(len(t))*0.1\n","    y=smooth(x)\n","\n","    see also:\n","\n","    numpy.hanning, numpy.hamming, numpy.bartlett, numpy.blackman, numpy.convolve\n","    scipy.signal.lfilter\n","\n","    TODO: the window parameter could be the window itself if an array instead of a string\n","    NOTE: length(output) != length(input), to correct this: return y[(window_len/2-1):-(window_len/2)] instead of just y.\n","    \"\"\"\n","\n","    if x.ndim != 1:\n","        raise ValueError, \"smooth only accepts 1 dimension arrays.\"\n","\n","    if x.size < window_len:\n","        raise ValueError, \"Input vector needs to be bigger than window size.\"\n","\n","\n","    if window_len<3:\n","        return x\n","\n","\n","    if not window in ['flat', 'hanning', 'hamming', 'bartlett', 'blackman']:\n","        raise ValueError, \"Window is on of 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\"\n","\n","\n","    s=numpy.r_[x[window_len-1:0:-1],x,x[-1:-window_len:-1]]\n","    #print(len(s))\n","    if window == 'flat': #moving average\n","        w=numpy.ones(window_len,'d')\n","    else:\n","        w=eval('numpy.'+window+'(window_len)')\n","\n","    y=numpy.convolve(w/w.sum(),s,mode='valid')\n","\n","    edge = int( (window_len)/2 )\n","    #print \"edge: \", edge\n","    return y[edge:len(y)-edge]\n","\n","\n","def findTriggerTrace(trace, S2NThreshold):\n","    t0 = 0.0\n","    delta = float(trace.stats.delta)\n","    nPoints = int(trace.stats.npts)\n","    nVec = np.array( range(nPoints) )\n","    tt = t0 + nVec*delta\n","    traceData = trace.data\n","    trEnv = obspy.signal.filter.envelope(traceData)\n","\n","\n","    # Compute STA/LTA\n","    tNoise = 20 # secs\n","    tSig = 5  #secs\n","\n","    nNoise = tNoise/delta\n","    nSig = tSig/delta\n","    nWin = nNoise+nSig\n","\n","    trigger = []\n","\n","    for iPoint in nVec[0:nWin]:\n","        trigger.append(0.0)\n","\n","    for iPoint in nVec[nWin:nPoints]:\n","        LTA = np.average( trEnv[iPoint-nNoise:iPoint] )\n","        STA = np.average( trEnv[iPoint: iPoint+nSig] )\n","\n","        trigger.append(STA/LTA)\n","\n","    smoothTrig = smooth(np.array(trigger), nSig+1)\n","    nTrig = len(trigger)\n","    findTrig = 0\n","\n","    # Define search betweeen 100 secs and 240 secs?\n","    nStart = int(100/delta)\n","    nStop = int(240/delta)\n","    for iTrig in range(nStart,nStop,1):\n","        if ( smoothTrig[iTrig] > S2NThreshold):\n","            findTrig = iTrig\n","            break\n","\n","    # Return timing of phase, for use by BandCheck, and traceTagQC...\n","    return tt[findTrig], smoothTrig\n","\n","def traceTagTimeSlow(threeCompStrm, travelTimeDic, pTime):\n","    \"tag the header t0 with first arrival phase name\"\n","\n","    # Write Phase Name, Phase Slowness and Phase ?\n","    for iCmp in range(3):\n","        #print \"trace: \", iCmp, \" of \", len(threeCompStrm)\n","        threeCompStrm[iCmp].stats.sac['t0'] = pTime\n","        threeCompStrm[iCmp].stats.sac['user0'] =  travelTimeDic['dT/dD']\n","        threeCompStrm[iCmp].stats.sac['kt0'] =  travelTimeDic['phase_name']\n","\n","\n","def traceTagQC(threeCompStrm, pTime):\n","    \"tag the header t1, to indicate QC pass\"\n","\n","    # Put QC tag in here ...\n","    for iCmp in range(3):\n","        threeCompStrm[iCmp].stats.sac['t1'] = pTime\n","\n","    # Write a phase picking routine hear new ...\n","\n","\n","def read3Channels(DataDir, fileMantissa, Fileformat):\n","    #Code snippet to take file name, and return 3component Stream.\n","    \"Code snippet to take file name, and return 3component Stream.\"\n","    vertFile = fileMantissa+\"BHZ\";\n","    radFile = fileMantissa+\"BHN\";\n","    transFile = fileMantissa+\"BHE\"\n","    #print \"Names: \", vertFile, radFile, transFile;\n","    # read each record triplet, and display ...\n","    threeCompStrm = read(DataDir + '/' + vertFile);\n","    threeCompStrm += read(DataDir + '/' + radFile);\n","    threeCompStrm += read(DataDir + '/' + transFile);\n","    return threeCompStrm\n","\n","def preProcessStream(threeCompStrm, noiseWindowSec, signalWindowSec):\n","    \"Slice Trace, Demean, Detrend, and HighPass?\"\n","    # noiseWindowSec : time before arrival P time\n","    # signalWindowSec : time after arrival P time\n","\n","    #!!!! ................................. Load Depth, Distance, Then Compute Travel Time\n","    evntDistDeg = threeCompStrm[0].stats.sac['gcarc'];\n","    evntDep = threeCompStrm[0].stats.sac['evdp'];\n","    strtTime = threeCompStrm[0].stats['starttime'];\n","    tt = getTravelTimes(delta=evntDistDeg, depth = evntDep, model='ak135')\n","    pTime = tt[0]['time']\n","\n","    biasLeft = noiseWindowSec; biasRight = signalWindowSec\n","    #print \"Windows ...\", biasLeft, biasRight, \"Time \", strtTime\n","\n","    #1. Slice And Tag ...\n","    #threeTrace = []\n","    #for iCmp in range(3):\n","    procStream =  threeCompStrm.slice(strtTime+pTime - biasLeft, strtTime+pTime+biasRight,\n","                                            keep_empty_traces=False)\n","\n","    if (len(procStream) == 3):\n","        #procStream = Stream(traces=threeTrace)\n","        #print procStream\n","        traceTagTimeSlow(procStream, tt[0], biasLeft)\n","\n","        # Demean, Detrend, and, HighPass? Yes with 50s [1/50 = 0.02 Hz]  *******\n","        lowFreq = 0.02\n","        procStream.detrend(type=\"demean\"); procStream.detrend(type=\"simple\")\n","        procStream.filter(\"highpass\", freq=lowFreq)\n","        #print procStream\n","        return procStream\n","    else:\n","        #print \"Slice failed!\"\n","        return procStream\n","\n","\n","\n","\n","\n","\n","def readHeaders(trace):\n","    \"Read relevant header information ...\"\n","    return {'gcarc': trace.stats.sac['gcarc'], 'evdp':trace.stats.sac['evdp'],\n","            'starttime':trace.stats['starttime'], 'o': trace.stats['sac']['o'], 'delta': trace.stats['delta'],\n","            'baz':trace.stats.sac['baz']}\n","\n","def rotateStream2ZRT(threeCompStrm, H1Azim):\n","    \"Load 3 component stream and rotate from ZNE into ZRT.\"\n","\n","    #rotate_new from krischer / obspy might be useful ..\n","    baz = threeCompStrm[1].stats.sac['baz']\n","\n","\n","    dipZcomp = -90; dipH1comp = 0.0; dipH2comp = 0.0\n","    azimZcomp = 0; azimH1comp = H1Azim; azimH2comp = (H1Azim + 90.0) % 360\n","    #print \"H1 azim: \", azimH1comp, \"H2 azim: \", azimH2comp\n","    zData = threeCompStrm[0].data ; H1Data = threeCompStrm[1].data ; H2Data = threeCompStrm[2].data;\n","\n","    [Z, N, E] = rotate_new.rotate2ZNE(zData, azimZcomp, dipZcomp, H1Data, azimH1comp, dipH1comp, \\\n","                                      H2Data,azimH2comp, dipH2comp)\n","\n","    #N = threeCompStrm[1].data ; E = threeCompStrm[2].data;\n","\n","\n","    [R, T] = rotate_new.rotate_NE_RT(N, E, baz)\n","\n","    threeCompStrm[0].data = Z\n","    threeCompStrm[1].data = R\n","    threeCompStrm[2].data = T\n","\n","\n","\n","def saveStream(threeCompStrm, outDir, fileMantissa):\n","    # Code Snippet to Take Processed Stream and Save to Hard-Disk\"\n","    \"Save Stream to Directory, Default Output is SAC file ...\"\n","    #print \"Saving trace to: \", outDir+fileMantissa+\".[ZRT]\"\n","\n","    vertFile = fileMantissa+\"Z\";\n","    radFile = fileMantissa+\"R\";\n","    transFile = fileMantissa+\"T\"\n","\n","    if (os.path.isdir(outDir) ):\n","        #print \"Dir exists: \"\n","        threeCompStrm[0].write(outDir + vertFile, format=\"SAC\")\n","        threeCompStrm[1].write(outDir + radFile, format=\"SAC\")\n","        threeCompStrm[2].write(outDir + transFile, format=\"SAC\")\n","    else:\n","        #print \"Make Directory, then save..\"\n","        os.makedirs(outDir)\n","        threeCompStrm[0].write(outDir + vertFile, format=\"SAC\")\n","        threeCompStrm[1].write(outDir + radFile, format=\"SAC\")\n","        threeCompStrm[2].write(outDir + transFile, format=\"SAC\")\n","\n","\n","def runBandCheckQC(threeCompStrm, noiseWin, signalWin):\n","    from copy import deepcopy\n","    # run signal to noise in each window and tag phas appropriately\n","    #################### FREQ Windows\n","    cornerFreq = 0.07\n","    lowFreqA = 0.07\n","    highFreqA = 0.25\n","    lowFreqB = 0.25\n","    highFreqB = 2\n","    #################### End FREQ Windows\n","\n","    # Make copy of stream ...\n","    lowFrqStrm = deepcopy(threeCompStrm)\n","    midFrqStrm = deepcopy(threeCompStrm)\n","    highFrqStrm = deepcopy(threeCompStrm)\n","\n","    # Band Pass these Copies\n","    #lowFrqStrm.filter(\"lowpass\", freq=cornerFreq);\n","    lowFrqStrm.filter(\"bandpass\", freqmin=0.01, freqmax=0.07, corners=2);\n","    midFrqStrm.filter(\"bandpass\", freqmin=lowFreqA, freqmax=highFreqA);\n","    highFrqStrm.filter(\"bandpass\", freqmin=lowFreqB, freqmax=highFreqB);\n","\n","    zTraceBands = []\n","    zEnvlpBands = []\n","    zComps = []\n","    allSigNoise = []\n","\n","    # Default trigger Time to predicted time for P arrival from TauP\n","    trigTimeBands = [100, 100, 100]\n","    colors = ['b', 'g', 'k']\n","    pickFuncBands = []\n","\n","    # Pick Out vertical Components of Bands and append to list for signal analysis\n","    zTraceBands.append(lowFrqStrm[0])\n","    zEnvlpBands.append( obspy.signal.filter.envelope(lowFrqStrm[0].data) )\n","    zComps.append( lowFrqStrm[0].data )\n","\n","    zTraceBands.append( midFrqStrm[0] )\n","    zEnvlpBands.append( obspy.signal.filter.envelope(midFrqStrm[0].data) )\n","    zComps.append( midFrqStrm[0].data )\n","\n","    zTraceBands.append( highFrqStrm[0] )\n","    zEnvlpBands.append( obspy.signal.filter.envelope(highFrqStrm[0].data) )\n","    zComps.append( highFrqStrm[0].data )\n","\n","\n","    plt.figure(figsize=(10,4))\n","\n","    # Iterate through bands and do signal to noise computation ...\n","    envMax = 0\n","    envMin = 0\n","    for iterBands in range( len(zEnvlpBands) ):\n","\n","        plt.subplot(4,1,iterBands+1)\n","\n","        zTraceBand = zTraceBands[iterBands]\n","        zEnvlpBand = zEnvlpBands[iterBands]\n","        zComp = zComps[iterBands]\n","\n","        t = np.linspace(0, noiseWin+signalWin, len(zEnvlpBand) )\n","        noise =  zEnvlpBand[t<100];  signal =  zEnvlpBand[t >100];\n","\n","        sig2noise = np.average(np.absolute(signal)) / np.average(np.absolute(noise));\n","        allSigNoise.append( sig2noise )\n","        print \"Signal to Noise: \", np.average(np.absolute(signal)), np.average(np.absolute(noise)), sig2noise\n","\n","        plt.plot(t, zComp, colors[iterBands])\n","        plt.plot(t, zEnvlpBand, 'm')\n","\n","        envMax = np.amax( zEnvlpBands )\n","        envMin = np.amin( zComps )\n","\n","\n","\n","        # If good ... Calculate trigger and plot too ..\n","        maxS2N = 1.6\n","        trigThreshold = 2.0\n","\n","        # There should be 3 triggers for each frequency window ...\n","        tTrig, pickFunc = findTriggerTrace(zTraceBand, trigThreshold)\n","        trigTimeBands[iterBands] = tTrig\n","        pickFuncBands.append(pickFunc)\n","\n","        if( sig2noise > maxS2N):\n","            plt.plot(t[0:len(noise)], noise, 'r')\n","\n","\n","\n","    sig2noiseMax = np.amax(allSigNoise)\n","    bandWithMax = np.argmax(allSigNoise)\n","    print \"Maximum Signal to Noise across 3 Frequency bands: \", sig2noiseMax\n","\n","\n","    if( sig2noiseMax > maxS2N):\n","        #traceTagQC(threeCompStrm, noiseWin)  ## OLD TAG WITH 100sec. Predicted Arrival\n","        traceTagQC(threeCompStrm, trigTimeBands[bandWithMax])\n","        tagStatus = True\n","\n","        # Print predicted timing for trigger ...\n","        plt.vlines(trigTimeBands[bandWithMax], envMin, envMax)\n","\n","    else:\n","        tagStatus = False\n","\n","    plt.subplot(4,1,4)\n","    plt.plot(t, pickFuncBands[0], colors[0] )\n","    plt.plot(t, pickFuncBands[1], colors[1] )\n","    plt.plot(t,  pickFuncBands[2], colors[2])\n","    plt.hlines(trigThreshold, 0,299)\n","    plt.show()\n","    return tagStatus;\n","\n","\n","########################### END OF FUNCTION DEFINITIONS #########################################################\n","#!!!!!!!!!!!!!!!!!!!!!!!!!!! BEGIN WORKFLOW HERE ...... !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n","##++--- ---+ !!!!!!! Work on Work flow using the helper functions now ...\n","inDir = \"/Users/tmo22/Documents/JapaneseProject/RawData/borehole.farm/farmSAC/\"\n","stationDirs = ['WP1/', 'WP2/']\n","\n","outDir = \"/Users/tmo22/Documents/JapaneseProject/ProcData/borehole/\"\n","\n","\n","# Select particular station - and parse to method to return list of files\n","\n","stationAzim = {'WP1/':315, 'WP2/':156}\n","\n","for stationDir in stationDirs[0:1]:\n","#for stationDir in stationDirs:\n","\n","    for iterStation in range(0,1,1):\n","    #for iterStation in range( len(stations) ):\n","        # Use shell command to recover all vertical records\n","        DataDir = inDir + stationDirs[iterStation]\n","        Hor1Azim = stationAzim[ stationDirs[iterStation] ]\n","        DataFiles = !ls $DataDir/*Z\n","\n","        numRecs = len(DataFiles)\n","\n","        listGoodTraces = []\n","        cntGoodTraces = 0\n","\n","        cntFail = 0\n","\n","\n","        #for iterDataFile in range(0,20,1):\n","        for iterDataFile in range(len(DataFiles)):\n","\n","            # Pick out file name ...\n","            DataFile = DataFiles[iterDataFile]\n","            fileSplit = DataFile.split('/'); indxLast = len(fileSplit); fileName =  fileSplit[indxLast-1];\n","            fileHead = fileName[0:len(fileName)-3]\n","\n","            # ....................................0. Display SCAN status\n","            print \"Dir: \", inDir\n","            print \"Station: \", stationDirs[iterStation]\n","            print \"H1 Orientation Azim \", Hor1Azim\n","            print \"Number of records: \", numRecs;\n","            print \"Reading \", DataDir + fileHead, \"File \", iterDataFile, \" of \", len(DataFiles)\n","            print \"No of QC tagged records: \", cntGoodTraces, \"List:  \", listGoodTraces\n","            print \"No of records fail slice: \", cntFail\n","\n","            #  ................................... 1. READ!\n","            threeCompStrm = read3Channels(DataDir, fileHead, \"SAC\")\n","            #threeCompStrm[0].plot(); threeCompStrm[1].plot(); threeCompStrm[2].plot();\n","\n","            # Trace slicing parameters.........  2. prePROCESS!\n","            noiseWindow = 100; signalWindow = 600\n","            procStrm = preProcessStream(threeCompStrm,noiseWindow, signalWindow)\n","\n","            if (len(procStrm) == 3 and ( len(procStrm[1]) == len(procStrm[2]) ) ):\n","                #procStrm.plot()\n","                #procStrm[0].plot(type=\"relative\", number_of_ticks=4);\n","                #procStrm[1].plot(type=\"relative\", number_of_ticks=4);\n","                #procStrm[2].plot(type=\"relative\", number_of_ticks=4);\n","\n","                # ............................ 3.ROTATE! ADD Station Azim Here...\n","                rotateStream2ZRT(procStrm, Hor1Azim)\n","                #procStrm[0].plot(type=\"relative\", number_of_ticks=4);  procStrm[1].plot(type=\"relative\", number_of_ticks=4);\n","                #procStrm[2].plot(type=\"relative\", number_of_ticks=4);\n","                #print readHeaders(procStrm[0]), #readHeaders(procStrm[1]), readHeaders(procStrm[2])\n","\n","\n","                # ............................. 4. doQC and TAGPHASE ..\n","                isGood = runBandCheckQC(procStrm, noiseWindow, signalWindow)\n","\n","                if (isGood):\n","                    listGoodTraces.append(iterDataFile)\n","                    cntGoodTraces += 1\n","\n","                #procStrm[0].plot(type=\"relative\", number_of_ticks=4)\n","\n","                #time.sleep(5)\n","                clear_output()\n","\n","\n","                # ............................. 5. saveSTREAM to outputDIR ..\n","                outDirSave = outDir + stationDirs[iterStation]\n","                saveStream(procStrm, outDirSave, fileHead)\n","            else:\n","                cntFail += 1\n","\n","\n","\n"],"outputs":[],"metadata":{"id":"xujyS20Dw_mb"},"execution_count":null},{"cell_type":"code","source":["# Code to test phase picker using STA/LTA with 5 sec. signal window and (5*4=20 sec.) noise window\n","# first reconstruct time signal from data headers\n","#print procStrm[0].stats\n","\n","# Demo using single good data ...\n","\n","\n","def smooth(x,window_len=11,window='hanning'):\n","    \"\"\" http://wiki.scipy.org/Cookbook/SignalSmoothsmooth the data using a window with requested size.\n","\n","    This method is based on the convolution of a scaled window with the signal.\n","    The signal is prepared by introducing reflected copies of the signal\n","    (with the window size) in both ends so that transient parts are minimized\n","    in the begining and end part of the output signal.\n","\n","    input:\n","        x: the input signal\n","        window_len: the dimension of the smoothing window; should be an odd integer\n","        window: the type of window from 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\n","            flat window will produce a moving average smoothing.\n","\n","    output:\n","        the smoothed signal\n","\n","    example:\n","\n","    t=linspace(-2,2,0.1)\n","    x=sin(t)+randn(len(t))*0.1\n","    y=smooth(x)\n","\n","    see also:\n","\n","    numpy.hanning, numpy.hamming, numpy.bartlett, numpy.blackman, numpy.convolve\n","    scipy.signal.lfilter\n","\n","    TODO: the window parameter could be the window itself if an array instead of a string\n","    NOTE: length(output) != length(input), to correct this: return y[(window_len/2-1):-(window_len/2)] instead of just y.\n","    \"\"\"\n","\n","    if x.ndim != 1:\n","        raise ValueError, \"smooth only accepts 1 dimension arrays.\"\n","\n","    if x.size < window_len:\n","        raise ValueError, \"Input vector needs to be bigger than window size.\"\n","\n","\n","    if window_len<3:\n","        return x\n","\n","\n","    if not window in ['flat', 'hanning', 'hamming', 'bartlett', 'blackman']:\n","        raise ValueError, \"Window is on of 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\"\n","\n","\n","    s=numpy.r_[x[window_len-1:0:-1],x,x[-1:-window_len:-1]]\n","    #print(len(s))\n","    if window == 'flat': #moving average\n","        w=numpy.ones(window_len,'d')\n","    else:\n","        w=eval('numpy.'+window+'(window_len)')\n","\n","    y=numpy.convolve(w/w.sum(),s,mode='valid')\n","\n","    edge = int( (window_len)/2 )\n","    print \"edge: \", edge\n","    return y[edge:len(y)-edge]\n","\n","\n","procStrm = read(\"/Users/tmo22/Documents/JapaneseProject/ProcData/boreHole/WP2/200203260345.Z\")\n","t0 = 0.0\n","delta = float(procStrm[0].stats.delta)\n","nPoints = int(procStrm[0].stats.npts)\n","nVec = np.array( range(nPoints) )\n","tt = t0 + nVec*delta\n","trace = procStrm[0].data\n","trEnv = obspy.signal.filter.envelope(trace)\n","\n","#print type(nVec)\n","print nVec[nPoints-1:nPoints], tt[nPoints-1:nPoints]\n","plt.plot(tt, trace, tt, trEnv)\n","plt.show()\n","\n","\n","# Compute STA/LTA\n","tNoise = 20 # secs\n","tSig = 5  #secs\n","\n","nNoise = tNoise/delta\n","nSig = tSig/delta\n","nWin = nNoise+nSig\n","\n","trigger = []\n","\n","for iPoint in nVec[0:nWin]:\n","    trigger.append(0.0)\n","\n","for iPoint in nVec[nWin:nPoints]:\n","    LTA = np.average( trEnv[iPoint-nNoise:iPoint] )\n","    STA = np.average( trEnv[iPoint: iPoint+nSig] )\n","\n","    trigger.append(STA/LTA)\n","\n","nTrig = len(trigger)\n","trigVal = 2.0\n","findTrig = 0\n","\n","for iTrig in range(nTrig):\n","    if ( trigger[iTrig] > trigVal):\n","        findTrig = iTrig\n","        break\n","\n","\n","\n","convTrig = smooth(np.array(trigger), nSig+1)\n","print \"convLen: \", len(convTrig), \"trigLen: \", len(trigger), \"sigWIn: \", nSig\n","\n","#plt.plot(tt[0:nTrig], trigger[0:nTrig], tt, convTrig)\n","#plt.show()\n","\n","#print \"convLen: \", len(convTrig), \"trigLen: \", len(trigger)\n","#plt.plot(hanTaper)\n","plt.plot(convTrig)\n","plt.plot(trigger)\n","plt.show()\n","\n","envMax = np.max(trEnv)\n","envMin = np.min(trace)\n","\n","plt.plot(tt, trace, tt, trEnv)\n","plt.vlines(tt[findTrig], envMin, envMax)\n","plt.show()"],"outputs":[{"output_type":"stream","text":["[6000] [ 300.]\n"],"name":"stdout"},{"output_type":"display_data","data":{},"metadata":{}},{"output_type":"stream","text":["edge:  50\n","convLen:  6001 trigLen:  6001 sigWIn:  100.0\n"],"name":"stdout"},{"output_type":"display_data","data":{},"metadata":{}},{"output_type":"display_data","data":{},"metadata":{}}],"metadata":{"id":"Q9oo5u4Nw_mc","outputId":"a74cce07-15e2-4e64-8af8-349d789fa661"},"execution_count":null},{"cell_type":"code","source":["plt.hlines?"],"outputs":[],"metadata":{"id":"iJpQaNQmw_md"},"execution_count":null},{"cell_type":"code","source":["np.amin?"],"outputs":[],"metadata":{"id":"zftaV8oVw_md"},"execution_count":null},{"cell_type":"code","source":["print seedMeta"],"outputs":[{"output_type":"stream","text":["Networks:\n","\tPS (Deep-Sea Borehole Stations)\n","Stations:\n","\tPS.WP2 (Western Pacific borehole station WP2)\n","Channels:\n","\tPS.WP2..BHE | 100.00 Hz | CMG-1T | 2000-07-11 -  | Lat: 41.1, Lng: 160.0\n","\tPS.WP2..BHN | 100.00 Hz | CMG-1T | 2000-07-11 -  | Lat: 41.1, Lng: 160.0\n","\tPS.WP2..BHZ | 100.00 Hz | CMG-1T | 2000-07-11 -  | Lat: 41.1, Lng: 160.0\n"],"name":"stdout"}],"metadata":{"id":"XXfipPJ4w_md","outputId":"804c84f5-8fb4-49a6-d7e0-94b68d524bb6"},"execution_count":null},{"cell_type":"code","source":["metaA =  seedMeta.getCoordinates(\"PS.WP2..BHE\")\n","metaB = seedMeta.getCoordinates(\"PS.WP2..BHE\")\n","\n","print metaA, metaB\n","\n","metaC = dict(metaA.items() + metaB.items() )\n","\n","print metaC"],"outputs":[{"output_type":"stream","text":["{'latitude': 41.0797, 'local_depth': 0.0, 'elevation': -6036.7, 'longitude': 159.9632} {'latitude': 41.0797, 'local_depth': 0.0, 'elevation': -6036.7, 'longitude': 159.9632}\n","{'latitude': 41.0797, 'local_depth': 0.0, 'elevation': -6036.7, 'longitude': 159.9632}\n"],"name":"stdout"}],"metadata":{"id":"Bda9VSlvw_md","outputId":"54bc89f1-9105-4e51-9659-24b3d51da2bd"},"execution_count":null},{"cell_type":"code","source":[],"outputs":[],"metadata":{"id":"ghUaR0gsw_me"},"execution_count":null}]}